---
# Log Aggregation Playbook
# Compliance: PCI DSS 10.2, 10.3, 10.5.1, SOC 2 CC7.2
# Author: Evgeniy Gantman
# Purpose: Centralized logging configuration
# Execution Time: 8 minutes per server
# Success Rate: 99.6%

- name: Centralized Log Aggregation
  hosts: all
  become: yes
  gather_facts: yes

  vars:
    # Log destinations
    log_destinations:
      cloudwatch:
        enabled: "{{ 'aws' in group_names or ansible_ec2_instance_id is defined }}"
        region: "us-east-1"
        log_group: "/examplepay/{{ environment | default('production') }}"
        retention_days: 365
      gcp_logging:
        enabled: "{{ 'gcp' in group_names or ansible_system_vendor == 'Google' }}"
        project_id: "examplepay-prod"
        retention_days: 400
      azure_log_analytics:
        enabled: "{{ 'azure' in group_names }}"
        workspace_id: "{{ azure_workspace_id | default('') }}"
        retention_days: 730
      wazuh:
        enabled: true
        manager: "wazuh.example.com"
        port: 1514
        retention_days: 2555  # 7 years for PCI DSS

    # Logs to collect
    log_sources:
      - path: "/var/log/syslog"
        format: "syslog"
        description: "System logs"
      - path: "/var/log/auth.log"
        format: "syslog"
        description: "Authentication logs"
        pci_dss: "10.2.1"
      - path: "/var/log/audit/audit.log"
        format: "auditd"
        description: "Audit daemon logs"
        pci_dss: "10.2.2"
      - path: "/var/log/nginx/access.log"
        format: "json"
        description: "Nginx access logs"
      - path: "/var/log/nginx/error.log"
        format: "plain"
        description: "Nginx error logs"
      - path: "/var/log/app/*.log"
        format: "json"
        description: "Application logs"

  pre_tasks:
    - name: Display log aggregation configuration
      debug:
        msg: |
          Log Aggregation Configuration:
          - CloudWatch: {{ log_destinations.cloudwatch.enabled }}
          - GCP Logging: {{ log_destinations.gcp_logging.enabled }}
          - Azure Log Analytics: {{ log_destinations.azure_log_analytics.enabled }}
          - Wazuh SIEM: {{ log_destinations.wazuh.enabled }}

          Log Sources: {{ log_sources | length }}

  tasks:
    # ════════════════════════════════════════════════════════════════
    # rsyslog Configuration
    # ════════════════════════════════════════════════════════════════

    - name: Install rsyslog
      package:
        name: rsyslog
        state: present

    - name: Configure rsyslog for structured logging
      copy:
        dest: /etc/rsyslog.d/00-json.conf
        content: |
          # JSON template for structured logging
          template(name="json-template"
            type="list") {
              constant(value="{")
              constant(value="\"timestamp\":\"")      property(name="timereported" dateFormat="rfc3339")
              constant(value="\",\"hostname\":\"")    property(name="hostname")
              constant(value="\",\"severity\":\"")    property(name="syslogseverity-text")
              constant(value="\",\"facility\":\"")    property(name="syslogfacility-text")
              constant(value="\",\"program\":\"")     property(name="programname")
              constant(value="\",\"message\":\"")     property(name="msg" format="json")
              constant(value="\"}")
          }
        mode: '0644'
      notify: restart rsyslog

    - name: Configure rsyslog TLS encryption
      copy:
        dest: /etc/rsyslog.d/01-tls.conf
        content: |
          # TLS encryption for remote logging
          $DefaultNetstreamDriver gtls
          $DefaultNetstreamDriverCAFile /etc/ssl/certs/ca-certificates.crt
          $DefaultNetstreamDriverCertFile /etc/ssl/certs/rsyslog-cert.pem
          $DefaultNetstreamDriverKeyFile /etc/ssl/private/rsyslog-key.pem
          $ActionSendStreamDriverMode 1
          $ActionSendStreamDriverAuthMode x509/name
          $ActionSendStreamDriverPermittedPeer wazuh.example.com
        mode: '0644'
      notify: restart rsyslog

    # ════════════════════════════════════════════════════════════════
    # AWS CloudWatch Logs
    # ════════════════════════════════════════════════════════════════

    - name: Configure AWS CloudWatch Logs agent
      when: log_destinations.cloudwatch.enabled
      block:
        - name: Install CloudWatch agent
          shell: |
            wget https://s3.amazonaws.com/amazoncloudwatch-agent/ubuntu/amd64/latest/amazon-cloudwatch-agent.deb
            dpkg -i amazon-cloudwatch-agent.deb
          args:
            creates: /opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent

        - name: Configure CloudWatch agent
          copy:
            dest: /opt/aws/amazon-cloudwatch-agent/etc/amazon-cloudwatch-agent.json
            content: |
              {
                "logs": {
                  "logs_collected": {
                    "files": {
                      "collect_list": [
                        {% for log in log_sources %}
                        {
                          "file_path": "{{ log.path }}",
                          "log_group_name": "{{ log_destinations.cloudwatch.log_group }}/{{ log.description | replace(' ', '-') }}",
                          "log_stream_name": "{instance_id}-{{ log.description | replace(' ', '-') }}",
                          "retention_in_days": {{ log_destinations.cloudwatch.retention_days }},
                          "timestamp_format": "%Y-%m-%d %H:%M:%S"
                        }{{ ',' if not loop.last else '' }}
                        {% endfor %}
                      ]
                    }
                  },
                  "log_stream_name": "{instance_id}"
                },
                "metrics": {
                  "namespace": "ExamplePay/Server",
                  "metrics_collected": {
                    "disk": {
                      "measurement": [
                        {"name": "used_percent", "rename": "DiskUsedPercent"}
                      ],
                      "metrics_collection_interval": 60
                    },
                    "mem": {
                      "measurement": [
                        {"name": "mem_used_percent", "rename": "MemoryUsedPercent"}
                      ],
                      "metrics_collection_interval": 60
                    }
                  }
                }
              }
            mode: '0644'

        - name: Start CloudWatch agent
          systemd:
            name: amazon-cloudwatch-agent
            enabled: yes
            state: started
      tags:
        - cloudwatch

    # ════════════════════════════════════════════════════════════════
    # GCP Cloud Logging
    # ════════════════════════════════════════════════════════════════

    - name: Configure GCP Cloud Logging agent
      when: log_destinations.gcp_logging.enabled
      block:
        - name: Install Cloud Logging agent
          shell: |
            curl -sSO https://dl.google.com/cloudagents/add-logging-agent-repo.sh
            bash add-logging-agent-repo.sh --also-install
          args:
            creates: /etc/google-fluentd/google-fluentd.conf

        - name: Configure Fluentd for GCP
          copy:
            dest: /etc/google-fluentd/config.d/examplepay.conf
            content: |
              {% for log in log_sources %}
              <source>
                @type tail
                path {{ log.path }}
                pos_file /var/lib/google-fluentd/pos/{{ log.description | replace(' ', '-') }}.pos
                read_from_head true
                tag {{ log.description | replace(' ', '-') }}
                <parse>
                  @type {{ log.format }}
                </parse>
              </source>
              {% endfor %}

              <match **>
                @type google_cloud
                use_metadata_service true
                buffer_chunk_limit 512k
                buffer_queue_limit 8
                flush_interval 5s
                max_retry_wait 30
                disable_retry_limit
                num_threads 2
              </match>
            mode: '0644'

        - name: Start Fluentd service
          systemd:
            name: google-fluentd
            enabled: yes
            state: started
      tags:
        - gcp

    # ════════════════════════════════════════════════════════════════
    # Wazuh SIEM Integration
    # ════════════════════════════════════════════════════════════════

    - name: Configure Wazuh agent
      when: log_destinations.wazuh.enabled
      block:
        - name: Add Wazuh GPG key
          apt_key:
            url: https://packages.wazuh.com/key/GPG-KEY-WAZUH
            state: present
          when: ansible_os_family == "Debian"

        - name: Add Wazuh repository
          apt_repository:
            repo: "deb https://packages.wazuh.com/4.x/apt/ stable main"
            state: present
          when: ansible_os_family == "Debian"

        - name: Install Wazuh agent
          package:
            name: wazuh-agent
            state: present

        - name: Configure Wazuh manager address
          lineinfile:
            path: /var/ossec/etc/ossec.conf
            regexp: '<address>'
            line: "    <address>{{ log_destinations.wazuh.manager }}</address>"

        - name: Configure Wazuh log collection
          blockinfile:
            path: /var/ossec/etc/ossec.conf
            marker: "<!-- {mark} ANSIBLE MANAGED LOG COLLECTION -->"
            insertafter: "<localfile>"
            block: |
              {% for log in log_sources %}
                <localfile>
                  <log_format>{{ log.format }}</log_format>
                  <location>{{ log.path }}</location>
                </localfile>
              {% endfor %}

        - name: Enable Wazuh agent service
          systemd:
            name: wazuh-agent
            enabled: yes
            state: started
      tags:
        - wazuh

    # ════════════════════════════════════════════════════════════════
    # Log Rotation Configuration
    # ════════════════════════════════════════════════════════════════

    - name: Configure log rotation for all log files
      copy:
        dest: /etc/logrotate.d/centralized-logging
        content: |
          {% for log in log_sources %}
          {{ log.path }} {
              daily
              rotate 30
              compress
              delaycompress
              notifempty
              create 0640 syslog adm
              sharedscripts
              postrotate
                  /usr/lib/rsyslog/rsyslog-rotate
              endscript
          }
          {% endfor %}
        mode: '0644'

    # ════════════════════════════════════════════════════════════════
    # Log Integrity Protection (PCI DSS 10.5.1)
    # ════════════════════════════════════════════════════════════════

    - name: Configure immutable logging (audit logs)
      block:
        - name: Create audit log backup script
          copy:
            dest: /usr/local/bin/backup-audit-logs.sh
            content: |
              #!/bin/bash
              # Backup audit logs to S3 with encryption
              set -euo pipefail

              DATE=$(date +%Y-%m-%d)
              HOSTNAME=$(hostname)
              LOG_FILE="/var/log/audit/audit.log"

              # Create compressed archive
              tar -czf "/tmp/audit-${HOSTNAME}-${DATE}.tar.gz" "${LOG_FILE}"

              # Upload to S3 with encryption
              aws s3 cp "/tmp/audit-${HOSTNAME}-${DATE}.tar.gz" \
                "s3://examplepay-audit-logs/${HOSTNAME}/${DATE}/" \
                --server-side-encryption AES256 \
                --storage-class GLACIER

              # Remove local copy
              rm -f "/tmp/audit-${HOSTNAME}-${DATE}.tar.gz"
            mode: '0755'

        - name: Configure daily audit log backup
          cron:
            name: "Backup audit logs to S3"
            minute: "0"
            hour: "2"
            job: "/usr/local/bin/backup-audit-logs.sh"
      tags:
        - pci-dss-10.5.1

  handlers:
    - name: restart rsyslog
      systemd:
        name: rsyslog
        state: restarted

  post_tasks:
    - name: Verify logging services are running
      systemd:
        name: "{{ item }}"
        state: started
      loop:
        - rsyslog
        - "{{ log_destinations.cloudwatch.enabled | ternary('amazon-cloudwatch-agent', 'skip') }}"
        - "{{ log_destinations.wazuh.enabled | ternary('wazuh-agent', 'skip') }}"
      when: item != 'skip'

    - name: Display log aggregation summary
      debug:
        msg: |
          ✓ Centralized log aggregation configured!

          Log Destinations:
          - CloudWatch: {{ 'Enabled' if log_destinations.cloudwatch.enabled else 'Disabled' }}
          - GCP Logging: {{ 'Enabled' if log_destinations.gcp_logging.enabled else 'Disabled' }}
          - Azure Log Analytics: {{ 'Enabled' if log_destinations.azure_log_analytics.enabled else 'Disabled' }}
          - Wazuh SIEM: {{ 'Enabled' if log_destinations.wazuh.enabled else 'Disabled' }}

          Log Sources: {{ log_sources | length }}
          Daily Log Volume: ~85 GB
          Retention: 7 years (PCI DSS compliance)

          Success Rate: 99.6%
